{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLPeasy Demo - OKCupid\n",
    "# Applied Machine Learning Days, Lausanne - 25 January 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo you will use NLPEasy to quickly setup a Pandas-based pipeline, enhanced with ML-Methods and pre-trained models (e.g. word embeddings, sentiment analysis). The results will then be saved in Elasticsearch and a Kibana dashboard is generated automatically to explore the texts and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the workshop you have 2 possibilities to participate:\n",
    "- **mybinder.org:** No setup needed, only a webbrowser, however only 1-2 GB RAM are available\n",
    "- **own laptop:** You need to install the python environment and either Docker or Elasticsearch+Kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why we have to variants of the executen, a small one for binder and a bigger one to use on your laptop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DOIT_SMALL = 'BINDER_PORT' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can overwrite the BINDER-setting if you need to or want to trye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOIT_SMALL = True\n",
    "\"DOIT_SMALL: {}\".format(DOIT_SMALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOIT_SMALL:\n",
    "    nrows_to_load, spacy_model, spacy_cols = 1000, 'en_core_web_sm', ['essay0']\n",
    "else:\n",
    "    nrows_to_load, spacy_model, spacy_cols = None, 'en_core_web_md', None\n",
    "\"nrows_to_load: {} spacy_model: {} spacy_cols: {}\".format(nrows_to_load, spacy_model, spacy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can later get the full processed data for analysis if you download (1.3GB)\n",
    "> <https://github.com/d-one/NLPeasy-workshop/releases/download/v0.1/okc_enriched.zip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mybinder.org\n",
    "\n",
    "Online version so now installation needed on your laptop - might even work on a laptop ;-)\n",
    "\n",
    "> <https://mybinder.org/v2/gh/d-one/NLPeasy-workshop/master?urlpath=lab> [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/d-one/NLPeasy-workshop/master?urlpath=lab)\n",
    "\n",
    "> With prepared-data: <https://mybinder.org/v2/gh/d-one/NLPeasy-workshop/elastic?urlpath=lab> [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/d-one/NLPeasy-workshop/elastic?urlpath=lab)\n",
    "\n",
    "However, there is only 1-2 GB of RAM available, which is tough for our example. Also if you loose your connection or close your laptop for 10 minutes your session is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation on your own Laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example to completely work you need to have Python at least in Version 3.6 installed.\n",
    "Also you need to have install and start either\n",
    "\n",
    "- **Docker** <https://www.docker.com/get-started>, direct download links for\n",
    "    [Mac (DMG)](https://download.docker.com/mac/stable/Docker.dmg) and\n",
    "    [Windows (exe)](https://download.docker.com/win/stable/Docker%20for%20Windows%20Installer.exe).\n",
    "- **Elasticsearch** and **Kibana**:\n",
    "<https://www.elastic.co/downloads/> or\n",
    "<https://www.elastic.co/downloads/elasticsearch-oss> (pure Apache licensed version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally before the workshop, on the terminal or inside this notebook issue in the terminal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "git clone https://github.com/d-one/nlpeasy-workshop\n",
    "cd nlpeasy-workshop\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last command downloads a spacy model for the english language -\n",
    "for the following you need to have at least it's `md` (=medium) version which has wordvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyse today a dataset using NLPeasy package. We will also need pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpeasy as ne\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`util` is part of the workshop repository and helps with accessing the Kibana dashboard on binder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elastic Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to running elastic instance on your local machine. If this can't be found, it will start an Open Source stack on your docker.\n",
    "\n",
    "By specifying mount_volume_prefix your Elastic data is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elk = ne.connect_elastic(elk_version='7.5.2',\n",
    "                         mount_volume_prefix='./elastic-data-all/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If it is started on docker it will on the first time pull the images (1.3GB)!\n",
    "BTW, this function is not blocking, i.e. the servers might only be active couple of seconds later.\n",
    "Setting mountVolumePrefix=\"./elastic-data/\" would keep the data of elastic in your\n",
    "filesystems and then the data survives container restarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On binder you do not have access to it's localhost. However set up some binder-jupyter magic so you can access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if util.BINDER:\n",
    "   util.display_kibana_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 'OK Cupid' dataset in this workshop (the anonymized legal version of it).\n",
    "Let's load the data and see what we have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc = pd.read_csv('https://github.com/rudeboybert/JSE_OkCupid/raw/master/profiles.csv.zip', nrows=nrows_to_load)\n",
    "okc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some categorical / continuous variables about the OK cupid customers:\n",
    "* body type\n",
    "* diet\n",
    "* education\n",
    "* relgion\n",
    "* sex\n",
    "* astro sign\n",
    "* preferences for alcohol, cigarettes, drugs\n",
    "* sexual orientation\n",
    "* relationship status\n",
    "* language\n",
    "* location\n",
    "\n",
    "\n",
    "But they also needed to answer some questions (textual data):\n",
    "\n",
    "* essay0- My self summary\n",
    "* essay1- What I’m doing with my life\n",
    "* essay2- I’m really good at\n",
    "* essay3- The first thing people usually notice about me\n",
    "* essay4- Favorite books, movies, show, music, and food\n",
    "* essay5- The six things I could never do without\n",
    "* essay6- I spend a lot of time thinking about\n",
    "* essay7- On a typical Friday night I am\n",
    "* essay8- The most private thing I am willing to admit\n",
    "* essay9- You should message me if...\n",
    "\n",
    "Source: https://github.com/rudeboybert/JSE_OkCupid/blob/master/okcupid_codebook.txt  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do some cleanup on the data first to make it ready for analysis.\n",
    "* Replace NaN values\n",
    "* Remove HTML tags\n",
    "* Height inch --> cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: replace NaN with '', replace '\\n' with ' ' \n",
    "okc = okc.replace(np.nan, '', regex=True)\n",
    "okc = okc.replace('\\n', ' ', regex=True)\n",
    "\n",
    "#2: remove html tags\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "fixcols = okc.columns[okc.columns.str.startswith('essay')]\n",
    "for col in fixcols:\n",
    "    okc[col] = [BeautifulSoup(text).get_text() for text in okc[col] ]\n",
    "    print(col + ' done.')\n",
    "\n",
    "okc['offspring'] = [BeautifulSoup(text).get_text() for text in okc['offspring'] ]\n",
    "okc['sign'] = [BeautifulSoup(text).get_text() for text in okc['sign'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert height in inches to cm\n",
    "okc['height_cm'] = round(pd.to_numeric(okc['height'])*2.54, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Lat/Long for location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kibana does not containt mappings of place names to geographical coordinates.\n",
    "We have provided a file to map coordinates to the city names so that we can plot it in Kibana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('city_coordinates.csv')\n",
    "okc = okc.merge(cities, how='left', left_on='location', right_on = 'city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc['all_free_text'] =   \\\n",
    "        okc['essay0'] + '\\n' + \\\n",
    "        okc['essay1'] + '\\n' + \\\n",
    "        okc['essay2'] + '\\n' + \\\n",
    "        okc['essay3'] + '\\n' + \\\n",
    "        okc['essay4'] + '\\n' + \\\n",
    "        okc['essay5'] + '\\n' + \\\n",
    "        okc['essay6'] + '\\n' + \\\n",
    "        okc['essay7'] + '\\n' + \\\n",
    "        okc['essay8'] + '\\n' + \\\n",
    "        okc['essay9']\n",
    "\n",
    "okc['geolocation'] = okc['lat'].astype(str) + ',' + okc['long'].astype(str) \n",
    "okc = okc.drop(columns = ['lat', 'long'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Let's construct some other features that could be interesting.\n",
    "Some of the categorical features are too verbose, and we want to make it shorter.\n",
    "E.g. from the pets column, we will summarise those that like dogs and those that have dogs into a 'likes_dogs' category, like so:\n",
    "\n",
    "The same we will do for the cat lovers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc['pets'].fillna('', inplace=True)\n",
    "okc['likes_dogs'] = 0\n",
    "okc.loc[okc['pets'].str.contains('likes dogs'), 'likes_dogs'] = 1\n",
    "okc.loc[okc['pets'].str.contains('has dogs'), 'likes_dogs'] = 1\n",
    "\n",
    "okc['likes_cats'] = 0\n",
    "okc.loc[okc['pets'].str.contains('likes cats'), 'likes_cats'] = 1\n",
    "okc.loc[okc['pets'].str.contains('has cats'), 'likes_cats'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc[['pets', 'likes_dogs', 'likes_cats']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, languages are stuffed into one column so let's take them apart.\n",
    "And let's count how many languages they speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split language column\n",
    "okc[['language0','language1','language2','language3','language4']] = okc['speaks'].str.split(pat=',',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc['count_languages'] = (okc[['language0', 'language1', 'language2','language3','language4']].notnull()).astype(int).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'religion' and 'sign' also indicated how much people care about the respective topic.\n",
    "Let's break it into a clean religion and a clean sign column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate religion\n",
    "okc[['religion_clean', 'religion_remainder']] = okc['religion'].str.split(pat='and|but',expand=True)\n",
    "# isolate astro sign\n",
    "okc[['sign_clean', 'sign_remainder']] = okc['sign'].str.split(pat='and|but',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc['sign_clean'] = okc['sign_clean'].str.strip()\n",
    "okc['sign_clean'] = okc['sign_clean'].replace('', np.nan)\n",
    "okc['sign_clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc['religion_clean'] = okc['religion_clean'].str.strip()\n",
    "okc['religion_clean'] = okc['religion_clean'].replace('', np.nan)\n",
    "okc['religion_clean'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with ethnicity, to get it separated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc[['eth0','eth1','eth2','eth3','eth4','eth5','eth6','eth7','eth8']] = okc['ethnicity'].str.split(pat=', ',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allright, we should be all set now to start our analysis.\n",
    "So let's deep dive into NLPeasy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLPeasy Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to construct pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ne.Pipeline(index='okc',\n",
    "                       text_cols=['all_free_text', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
    "                       num_cols = ['age', 'height_cm', 'income'],\n",
    "                       tag_cols=['body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', 'pets',\n",
    "                                 'religion', 'sex', 'sign', 'smokes', 'speaks', 'status', 'religion_clean',\n",
    "                                'sign_clean', 'eth0', 'likes_cats', 'likes_dogs'],\n",
    "                       geopoint_cols = ['geolocation'], \n",
    "                       elk=elk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters here mean the following:\n",
    "* `index` will be the name of the Elasticsearch index (something like a Database name).\n",
    "* `textCols` here you can specify which columns of the dataframe are textual.\n",
    "* `numCols` will be used for histograms in Kibana.\n",
    "* `tagCols` will be used for barplots in Kibana.\n",
    "* `geoPointCols` can be used to draw maps in Kibana.\n",
    "* `elk` is the Elastic stack we connected to above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add stages in the pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLPeasy pipelines can have as few or as many stages as you wish. Here we just use the following:\n",
    "* `VaderSentiment` is a nice rule-based sentiment prediction for english.\n",
    "* `Spacy` uses the `spacy` package together with it's language model - here english small (=sm) or medium (=md).\n",
    "    We use it for a couple of enrichments, as you will see below.\n",
    "\n",
    "There are more stages in NLPeasy you can use (e.g. RegexTag Extraction, Splitting) or you can define your own functions there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the pipeline should calculate sentiments to all of the text columns. The first parameter specifies for which column, the second one stipulates the name of the output column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline += ne.VaderSentiment('all_free_text' , 'sentiment')\n",
    "pipeline += ne.VaderSentiment('essay0', 'sentiment_summary')\n",
    "pipeline += ne.VaderSentiment('essay1', 'sentiment_life')\n",
    "pipeline += ne.VaderSentiment('essay2', 'sentiment_goodat')\n",
    "pipeline += ne.VaderSentiment('essay3', 'sentiment_noticeabout')\n",
    "pipeline += ne.VaderSentiment('essay4', 'sentiment_favorites')\n",
    "pipeline += ne.VaderSentiment('essay5', 'sentiment_6things')\n",
    "pipeline += ne.VaderSentiment('essay6', 'sentiment_thinkingabout')\n",
    "pipeline += ne.VaderSentiment('essay7', 'sentiment_Fridaynight')\n",
    "pipeline += ne.VaderSentiment('essay8', 'sentiment_privatething')\n",
    "pipeline += ne.VaderSentiment('essay9', 'sentiment_messageme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add NLPeasy's spaCy enrichemnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small environments (like on binder) do it just for one column. Also we then only use the small model which does not provide vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_cols = spacy_cols or ['all_free_text', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9']\n",
    "use_spacy_vecs = not spacy_model.endswith('_sm')\n",
    "\"spacy_model={} use_spacy_vecs={} spacy_cols={}\".format(spacy_model, use_spacy_vecs,spacy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spacy model takes ~30 secs to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline += ne.SpacyEnrichment(nlp=spacy_model,\n",
    "                               cols=spacy_cols,\n",
    "                               vec=use_spacy_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run the pipeline - Spacy needs some time to process, so these ~60000 messages take about 100 minutes to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this for a subset of the data as it will take too long otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okc_enriched = pipeline.process(okc.head(1000), write_elastic=True, batchsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kibana Dashboard of all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.create_kibana_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Kibana in webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.display_kibana_link() if util.BINDER else elk.kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, and you wonder what took so long in the upload?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline._tictoc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "filename = '{}_okc_enriched.pickle'.format(datetime.datetime.now())\n",
    "okc_enriched.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If elastic was started on Docker and you want to shutdown the servers issue:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ne.docker.stop_elastic_on_docker(\"nlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Warning*: If you didn't use a mountVolumePrefix when you started the servers, all the data in elastic and kibana will be lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
